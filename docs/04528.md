# 仅使用网络摄像头进行透视跟踪

> 原文:[https://hackaday.com/2009/12/11/19177/](https://hackaday.com/2009/12/11/19177/)

 <https://www.youtube.com/embed/Tdqk6fedeGY?version=3&rel=1&showsearch=0&showinfo=1&iv_load_policy=1&fs=1&hl=en-US&autohide=2&wmode=transparent>

</span> <p>[johny chung Lee]，吃你的心了。看看这些家伙在做什么，用<a href="http://instruct1.cit.cornell.edu/courses/ece576/FinalProjects/f2009/ty244_jgs33/ty244_jgs33/ty244_jgs33/highlevel.html" target="_blank">面部跟踪和沉浸式</a> <a href="http://instruct1.cit.cornell.edu/courses/ece576/FinalProjects/f2009/ty244_jgs33/ty244_jgs33/ty244_jgs33/highlevel.html" target="_blank"> 3d </a>作为他们在课堂上的最后一个项目。他们使用一个摄像头和一个 FPGA 来制作你在视频中看到的演示。面部跟踪是通过肤色来完成的，所以在某些环境下可能会有一些问题，但能够在不安装更多硬件的情况下与你进行视角转换是非常棒的。</p> <p>我们意识到这与[约翰尼]所做的完全不同。我们喜欢<a href="http://hackaday.com/2007/12/21/wiimote-head-tracking-desktop-vr-display/">【Johnny】的作品</a>，并且认为能够用一个便宜的游戏控制器完成这些东西是开创性的。我们只是情不自禁地从最终结果中得出相似之处。</p> <p>[谢谢布鲁斯]</p> </body> </html>